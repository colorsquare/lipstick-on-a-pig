{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install pickle5\n",
    "%pip install mpld3\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Bert Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "model = \"bert\"\n",
    "folder_num = \"1.\"\n",
    "save_path = f\"../data/extracted/{folder_num} {model}/{model}_word_\"\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open, Save, and Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "def dump_pklfile(file, filepath, size):\n",
    "\twith open(filepath, \"wb\") as f:\n",
    "\t\tif size == 0:\n",
    "\t\t\tpickle.dump(file, f)\n",
    "\t\telif size > 0:\n",
    "\t\t\tpickle.dump(file[:size], f)\n",
    "\t\telse:\n",
    "\t\t\tpickle.dump(file[size:], f)\n",
    "\n",
    "\n",
    "def open_pklfile(filepath, size):\n",
    "\twith open(filepath, \"rb\") as f:\n",
    "\t\tif size == 0:\n",
    "\t\t\treturn pickle.load(f)\n",
    "\t\treturn (pickle.load(f))[0:size]\n",
    "\n",
    "\n",
    "def extract_bert_embeddings(word_list):\n",
    "\t# tensor for stacking embeddings\n",
    "\tembeddings = torch.empty(0, device=device)\n",
    "\n",
    "\tfor word in tqdm(word_list):\n",
    "\t\t# Map the token strings to their vocabulary indeces.\n",
    "\t\tmarked_text = \"[CLS] \" + word + \" [SEP]\"\n",
    "\t\ttokenized_text = tokenizer.tokenize(marked_text)\n",
    "\t\t\n",
    "\t\t# handling such as \"wedding_dress\"\n",
    "\t\ttokenized_text = [token for token in tokenized_text if token != '_']\n",
    "\n",
    "\t\t# Split the sentence into tokens.\n",
    "\t\tindexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\t\tsegments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "\t\t# Convert inputs to PyTorch tensors\n",
    "\t\ttokens_tensor = torch.tensor([indexed_tokens], device=device)\n",
    "\t\tsegments_tensors = torch.tensor([segments_ids], device=device)\n",
    "\t\t\n",
    "\t\t# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\t# Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = model(tokens_tensor, segments_tensors).hidden_states\n",
    "\t\t\tlast_four_hidden_states = outputs[-4:]\n",
    "\t\t\tconcated_hidden_states = torch.cat(last_four_hidden_states, dim=2)\n",
    "\n",
    "\t\t\tfirst_last = torch.add(concated_hidden_states[:, 1], concated_hidden_states[:, -2])\n",
    "\t\t\tembeddings = torch.cat([embeddings, first_last])\n",
    "\n",
    "\t# print(embeddings.shape)\n",
    "\treturn torch.squeeze(embeddings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Gender Bias by Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import linalg as LA\n",
    "import scipy.stats\n",
    "import json \n",
    "import codecs\n",
    "\n",
    "\n",
    "# normalize word vectors\n",
    "def normalize(wv):    \n",
    "    norms = LA.norm(wv, dim=1)\n",
    "    wv = wv / norms[:, np.newaxis]\n",
    "    return wv\n",
    "\n",
    "\n",
    "# compute bias from BERT with he-she\n",
    "def compute_bias_by_projection_heshe(vocab, lim_wv, gender_word_embedding):\n",
    "    print(lim_wv.shape)\n",
    "    print(gender_word_embedding[0].shape)\n",
    "    males = torch.tensordot(lim_wv, gender_word_embedding[0], dims=1)\n",
    "    females = torch.tensordot(lim_wv, gender_word_embedding[1], dims=1)\n",
    "    d = {}\n",
    "    for w, m, f in zip(vocab, males, females):\n",
    "        d[w] = m - f\n",
    "    return d\n",
    "\n",
    "\n",
    "def extract_professions():\n",
    "    professions = []\n",
    "    with codecs.open('../data/lists/professions.json', 'r', 'utf-8') as f:\n",
    "        professions_data = json.load(f)\n",
    "    for item in professions_data:\n",
    "        professions.append(item[0].strip())\n",
    "    return professions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings: All (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26189/26189 [03:07<00:00, 139.37it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = open_pklfile(\"../data/extracted/0. original/original_word_2016_restricted_vocab.pkl\", 0)\n",
    "lim_wv = extract_bert_embeddings(vocab)\n",
    "dump_pklfile(lim_wv, f\"{save_path}2016_restricted_embeddings.pkl\", 0)\n",
    "\n",
    "lim_wv = normalize(lim_wv)\n",
    "w2i = {w: i for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:01<00:00, 146.21it/s]\n",
      "100%|██████████| 223/223 [00:01<00:00, 148.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26189, 3072])\n",
      "torch.Size([3072])\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/lists/male_word_file.txt\", 'r') as f:\n",
    "  male_words = [word.strip() for word in f.readlines()]\n",
    "\n",
    "with open(\"../data/lists/female_word_file.txt\", 'r') as f:\n",
    "  female_words = [word.strip() for word in f.readlines()]\n",
    "\n",
    "male_embeddings = extract_bert_embeddings(male_words)\n",
    "female_embeddings = extract_bert_embeddings(female_words)\n",
    "\n",
    "male_embedding = torch.sum(male_embeddings, dim = 0, keepdim = True)\n",
    "female_embedding = torch.sum(female_embeddings, dim = 0, keepdim = True)\n",
    "\n",
    "male_embeddings = normalize(male_embeddings)\n",
    "female_embeddings = normalize(female_embeddings)\n",
    "\n",
    "gender_word_embedding = torch.cat((male_embedding, female_embedding), 0)\n",
    "\n",
    "gender_bias_all = compute_bias_by_projection_heshe(vocab, lim_wv, gender_word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "sorted_g = sorted(gender_bias_all.items(), key=operator.itemgetter(1))\n",
    "females_w = [item[0] for item in sorted_g[:2500]]\n",
    "females_e = torch.empty(0, device=device)\n",
    "for w in females_w:\n",
    "    temp = torch.unsqueeze(lim_wv[w2i[w]], 0)\n",
    "    females_e = torch.cat([females_e, temp], dim=0)\n",
    "\n",
    "dump_pklfile(females_w, f\"{save_path}2016_female_2500_vocab.pkl\", 2500)\n",
    "dump_pklfile(females_e, f\"{save_path}2016_female_2500_embeddings.pkl\", 2500)\n",
    "\n",
    "sorted_g = sorted(gender_bias_all.items(), key=operator.itemgetter(1), reverse=True)\n",
    "males_w = [item[0] for item in sorted_g[:2500]]\n",
    "males_e = torch.empty(0, device=device)\n",
    "for w in males_w:\n",
    "    temp = torch.unsqueeze(lim_wv[w2i[w]], 0)\n",
    "    males_e = torch.cat([males_e, temp], dim=0)\n",
    "    \n",
    "dump_pklfile(males_w, f\"{save_path}2016_male_2500_vocab.pkl\", 2500)\n",
    "dump_pklfile(males_e, f\"{save_path}2016_male_2500_embeddings.pkl\", 2500)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings: All (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47698/47698 [06:27<00:00, 123.13it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = open_pklfile(\"../data/extracted/0. original/original_word_2018_restricted_vocab.pkl\", 0)\n",
    "lim_wv = extract_bert_embeddings(vocab)\n",
    "dump_pklfile(lim_wv, f\"{save_path}2018_restricted_embeddings.pkl\", 0)\n",
    "\n",
    "lim_wv = normalize(lim_wv)\n",
    "w2i = {w: i for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:01<00:00, 145.25it/s]\n",
      "100%|██████████| 223/223 [00:01<00:00, 151.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47698, 3072])\n",
      "torch.Size([3072])\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/lists/male_word_file.txt\", 'r') as f:\n",
    "  male_words = [word.strip() for word in f.readlines()]\n",
    "\n",
    "with open(\"../data/lists/female_word_file.txt\", 'r') as f:\n",
    "  female_words = [word.strip() for word in f.readlines()]\n",
    "\n",
    "male_embeddings = extract_bert_embeddings(male_words)\n",
    "female_embeddings = extract_bert_embeddings(female_words)\n",
    "\n",
    "male_embedding = torch.sum(male_embeddings, dim = 0, keepdim = True)\n",
    "female_embedding = torch.sum(female_embeddings, dim = 0, keepdim = True)\n",
    "\n",
    "male_embeddings = normalize(male_embeddings)\n",
    "female_embeddings = normalize(female_embeddings)\n",
    "\n",
    "gender_word_embedding = torch.cat((male_embedding, female_embedding), 0)\n",
    "\n",
    "gender_bias_all = compute_bias_by_projection_heshe(vocab, lim_wv, gender_word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "sorted_g = sorted(gender_bias_all.items(), key=operator.itemgetter(1))\n",
    "females_w = [item[0] for item in sorted_g[:2500]]\n",
    "females_e = torch.empty(0, device=device)\n",
    "\n",
    "for w in females_w:\n",
    "    temp = torch.unsqueeze(lim_wv[w2i[w]], 0)\n",
    "    females_e = torch.cat([females_e, temp], dim=0)\n",
    "\n",
    "dump_pklfile(females_w, f\"{save_path}2018_female_2500_vocab.pkl\", 2500)\n",
    "dump_pklfile(females_e, f\"{save_path}2018_female_2500_embeddings.pkl\", 2500)\n",
    "\n",
    "sorted_g = sorted(gender_bias_all.items(), key=operator.itemgetter(1), reverse=True)\n",
    "males_w = [item[0] for item in sorted_g[:2500]]\n",
    "males_e = torch.empty(0, device=device)\n",
    "\n",
    "for w in males_w:\n",
    "    temp = torch.unsqueeze(lim_wv[w2i[w]], 0)\n",
    "    males_e = torch.cat([males_e, temp], dim=0)\n",
    "    \n",
    "dump_pklfile(males_w, f\"{save_path}2018_male_2500_vocab.pkl\", 2500)\n",
    "dump_pklfile(males_e, f\"{save_path}2018_male_2500_embeddings.pkl\", 2500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings: Gender Word File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223/223 [00:01<00:00, 146.68it/s]\n",
      "100%|██████████| 223/223 [00:01<00:00, 148.57it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/lists/male_word_file.txt\", 'r') as f:\n",
    "  male_words = [word.strip() for word in f.readlines()]\n",
    "male_word_embs = extract_bert_embeddings(male_words)\n",
    "dump_pklfile(male_words, f\"{save_path}male_word_file_vocab.pkl\", 0)\n",
    "dump_pklfile(male_word_embs, f\"{save_path}male_word_file_embeddings.pkl\", 0)\n",
    "\n",
    "with open(\"../data/lists/female_word_file.txt\", 'r') as f:\n",
    "  female_words = [word.strip() for word in f.readlines()]\n",
    "female_word_embs = extract_bert_embeddings(female_words)\n",
    "dump_pklfile(female_words, f\"{save_path}female_word_file_vocab.pkl\", 0)\n",
    "dump_pklfile(female_word_embs, f\"{save_path}female_word_file_embeddings.pkl\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
