{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WOMAN_RE = re.compile(r'\\b(?:woman)\\b')\n",
    "MAN_RE = re.compile(r'\\b(?:man)\\b')\n",
    "PERSON_RE = re.compile(\n",
    "    r'\\b(?:woman|man|female|male|girl|boy|sister|brother|daughter|son|'\n",
    "    r'mother|father|aunt|uncle|grandmother|grandfather|American)\\b')\n",
    "\n",
    "\n",
    "SINGULAR_NOUN_TEMPLATES = (\n",
    "    'This is {article} {term}.',\n",
    "    'That is {article} {term}.',\n",
    "    'There is {article} {term}.',\n",
    "    'Here is {article} {term}.',\n",
    "    'The {term} is here.',\n",
    "    'The {term} is there.',\n",
    ")\n",
    "\n",
    "PLURAL_NOUN_TEMPLATES = (\n",
    "    'These are {term}.',\n",
    "    'Those are {term}.',\n",
    "    'They are {term}.',\n",
    "    'The {term} are here.',\n",
    "    'The {term} are there.',\n",
    ")\n",
    "\n",
    "def fill_template(template, term):\n",
    "    article = (\n",
    "        'an'\n",
    "        if (\n",
    "            (\n",
    "                term.startswith('honor') or any(\n",
    "                    term.startswith(c) for c in 'aeiouAEIOU'\n",
    "                )\n",
    "            ) and not (\n",
    "                term.startswith('European') or term.startswith('Ukrainian')\n",
    "            )\n",
    "        )\n",
    "        else 'a'\n",
    "    )\n",
    "    sentence = template.format(article=article, term=term)\n",
    "    return sentence[0].upper() + sentence[1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_term_sentences={\n",
    "    \"male\":[\n",
    "              \"This is a male.\",\n",
    "      \"That is a male.\",\n",
    "      \"There is a male.\",\n",
    "      \"Here is a male.\",\n",
    "      \"The male is here.\",\n",
    "      \"The male is there.\",\n",
    "      \"A male is a person.\",\n",
    "      \"These are males.\",\n",
    "      \"Those are males.\",\n",
    "      \"They are males.\",\n",
    "      \"The males are here.\",\n",
    "      \"The males are there.\",\n",
    "      \"Males are people.\",\n",
    "      \"This is a man.\",\n",
    "      \"That is a man.\",\n",
    "      \"There is a man.\",\n",
    "      \"Here is a man.\",\n",
    "      \"The man is here.\",\n",
    "      \"The man is there.\",\n",
    "      \"A man is a person.\",\n",
    "      \"These are men.\",\n",
    "      \"Those are men.\",\n",
    "      \"They are men.\",\n",
    "      \"The men are here.\",\n",
    "      \"The men are there.\",\n",
    "      \"Men are people.\",\n",
    "      \"This is a boy.\",\n",
    "      \"That is a boy.\",\n",
    "      \"There is a boy.\",\n",
    "      \"Here is a boy.\",\n",
    "      \"The boy is here.\",\n",
    "      \"The boy is there.\",\n",
    "      \"A boy is a person.\",\n",
    "      \"These are boys.\",\n",
    "      \"Those are boys.\",\n",
    "      \"They are boys.\",\n",
    "      \"The boys are here.\",\n",
    "      \"The boys are there.\",\n",
    "      \"Boys are people.\",\n",
    "      \"This is a brother.\",\n",
    "      \"That is a brother.\",\n",
    "      \"There is a brother.\",\n",
    "      \"Here is a brother.\",\n",
    "      \"The brother is here.\",\n",
    "      \"The brother is there.\",\n",
    "      \"A brother is a person.\",\n",
    "      \"These are brothers.\",\n",
    "      \"Those are brothers.\",\n",
    "      \"They are brothers.\",\n",
    "      \"The brothers are here.\",\n",
    "      \"The brothers are there.\",\n",
    "      \"Brothers are people.\",\n",
    "      \"He is here.\",\n",
    "      \"He is there.\",\n",
    "      \"Here he is.\",\n",
    "      \"There he is.\",\n",
    "      \"He is a person.\",\n",
    "      \"It is him.\",\n",
    "      \"This is him.\",\n",
    "      \"That is him.\",\n",
    "      \"This is his.\",\n",
    "      \"That is his.\",\n",
    "      \"There is his.\",\n",
    "      \"Here is his.\",\n",
    "      \"It is his.\",\n",
    "      \"His is there.\",\n",
    "      \"His is here.\",\n",
    "      \"This is a son.\",\n",
    "      \"That is a son.\",\n",
    "      \"There is a son.\",\n",
    "      \"Here is a son.\",\n",
    "      \"The son is here.\",\n",
    "      \"The son is there.\",\n",
    "      \"A son is a person.\",\n",
    "      \"These are sons.\",\n",
    "      \"Those are sons.\",\n",
    "      \"They are sons.\",\n",
    "      \"The sons are here.\",\n",
    "      \"The sons are there.\",\n",
    "      \"Sons are people.\"\n",
    "    ],\n",
    "    \"female\":[\n",
    "        \"This is a female.\",\n",
    "      \"That is a female.\",\n",
    "      \"There is a female.\",\n",
    "      \"Here is a female.\",\n",
    "      \"The female is here.\",\n",
    "      \"The female is there.\",\n",
    "      \"A female is a person.\",\n",
    "      \"These are females.\",\n",
    "      \"Those are females.\",\n",
    "      \"They are females.\",\n",
    "      \"The females are here.\",\n",
    "      \"The females are there.\",\n",
    "      \"Females are people.\",\n",
    "      \"This is a woman.\",\n",
    "      \"That is a woman.\",\n",
    "      \"There is a woman.\",\n",
    "      \"Here is a woman.\",\n",
    "      \"The woman is here.\",\n",
    "      \"The woman is there.\",\n",
    "      \"A woman is a person.\",\n",
    "      \"These are women.\",\n",
    "      \"Those are women.\",\n",
    "      \"They are women.\",\n",
    "      \"The women are here.\",\n",
    "      \"The women are there.\",\n",
    "      \"Women are people.\",\n",
    "      \"This is a girl.\",\n",
    "      \"That is a girl.\",\n",
    "      \"There is a girl.\",\n",
    "      \"Here is a girl.\",\n",
    "      \"The girl is here.\",\n",
    "      \"The girl is there.\",\n",
    "      \"A girl is a person.\",\n",
    "      \"These are girls.\",\n",
    "      \"Those are girls.\",\n",
    "      \"They are girls.\",\n",
    "      \"The girls are here.\",\n",
    "      \"The girls are there.\",\n",
    "      \"Girls are people.\",\n",
    "      \"This is a sister.\",\n",
    "      \"That is a sister.\",\n",
    "      \"There is a sister.\",\n",
    "      \"Here is a sister.\",\n",
    "      \"The sister is here.\",\n",
    "      \"The sister is there.\",\n",
    "      \"A sister is a person.\",\n",
    "      \"These are sisters.\",\n",
    "      \"Those are sisters.\",\n",
    "      \"They are sisters.\",\n",
    "      \"The sisters are here.\",\n",
    "      \"The sisters are there.\",\n",
    "      \"Sisters are people.\",\n",
    "      \"She is here.\",\n",
    "      \"She is there.\",\n",
    "      \"Here she is.\",\n",
    "      \"There she is.\",\n",
    "      \"She is a person.\",\n",
    "      \"It is her.\",\n",
    "      \"This is her.\",\n",
    "      \"That is her.\",\n",
    "      \"This is hers.\",\n",
    "      \"That is hers.\",\n",
    "      \"There is hers.\",\n",
    "      \"Here is hers.\",\n",
    "      \"It is hers.\",\n",
    "      \"Hers is there.\",\n",
    "      \"Hers is here.\",\n",
    "      \"This is a daughter.\",\n",
    "      \"That is a daughter.\",\n",
    "      \"There is a daughter.\",\n",
    "      \"Here is a daughter.\",\n",
    "      \"The daughter is here.\",\n",
    "      \"The daughter is there.\",\n",
    "      \"A daughter is a person.\",\n",
    "      \"These are daughters.\",\n",
    "      \"Those are daughters.\",\n",
    "      \"They are daughters.\",\n",
    "      \"The daughters are here.\",\n",
    "      \"The daughters are there.\",\n",
    "      \"Daughters are people.\"\n",
    "    ]\n",
    "\n",
    "}\n",
    "\n",
    "sentence_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "import codecs\n",
    "\n",
    "filename=\"../data/embeddings/orig_glove\"\n",
    "with codecs.open(filename + '.vocab', 'r', 'utf-8') as f_embed:\n",
    "        vocab = [line.strip() for line in f_embed]\n",
    "\n",
    "print(\"opened vocab\")\n",
    "#  = ['professor', 'programmer']\n",
    "tags = nltk.pos_tag(vocab)\n",
    "print(\"tagged\")\n",
    "nouns = [word for word, tag in tqdm(tags) if tag.startswith(\"N\")]\n",
    "print(nouns[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "# word_list=['Jaegil', 'Programmer', 'Homemaker']\n",
    "word_list=nouns[:1000]\n",
    "w2i = {w: i for i, w in enumerate(word_list)}\n",
    "\n",
    "sentence_list=[]\n",
    "for term in word_list:\n",
    "    singular_term=singularize(term)\n",
    "    # sentence_list_dict[term]=[]\n",
    "    sentences=[]\n",
    "    sentences+= [fill_template(template, singular_term) for template in SINGULAR_NOUN_TEMPLATES]\n",
    "    \n",
    "    plurar_term=pluralize(term)\n",
    "    sentences+= [fill_template(template, plurar_term) for template in PLURAL_NOUN_TEMPLATES]\n",
    "    sentence_list.append(sentences)\n",
    "    \n",
    "    \n",
    "\n",
    "# print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BERT embeddigns\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=model.to(device)\n",
    "model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bert_embeddings(sentence_list):\n",
    "\t#init for stacking embeddings\n",
    "\tembeddings = torch.empty(0, device=device)\n",
    "\t\n",
    "\tfor sentences in tqdm(sentence_list):\n",
    "\t\tembedding=torch.empty(0, device=device)\n",
    "\t\tfor sentence in sentences:\n",
    "\t\t\t\n",
    "\t\t\t# if (word in '___'):\n",
    "\t\t\t# \tcontinue\n",
    "\t\t\t# Map the token strings to their vocabulary indeces.\n",
    "\t\t\tmarked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\t\t\ttokenized_text = tokenizer.tokenize(marked_text)\n",
    "\t\t\t\n",
    "\t\t\t# handling such as \"wedding_dress\"\n",
    "\t\t\ttokenized_text = [token for token in tokenized_text if token != '_']\n",
    "\n",
    "\t\t\t# Split the sentence into tokens.\n",
    "\t\t\tindexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\t\t\tsegments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "\t\t\t# Convert inputs to PyTorch tensors\n",
    "\t\t\ttokens_tensor = torch.tensor([indexed_tokens], device=device)\n",
    "\t\t\tsegments_tensors = torch.tensor([segments_ids], device=device)\n",
    "\t\t\t\n",
    "\t\t\t# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n",
    "\t\t\tmodel.eval()\n",
    "\n",
    "\t\t\t#Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\toutputs = model(tokens_tensor, segments_tensors)\n",
    "\t\t\t\thidden_states=outputs[2]\n",
    "\t\t\t\t# print(hidden_states)\n",
    "\t\t\t\t# print(hidden_states.shape)\n",
    "\t\t\t\ttoken_vecs = hidden_states[-2][0]\n",
    "\t\t\t\tsentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\t\t\t\tsentence_embedding=torch.unsqueeze(sentence_embedding, dim= -1)\n",
    "\n",
    "\t\t\t\t# first_last = torch.add(concated_hidden_states[:, 1], concated_hidden_states[:, -2])\n",
    "\t\t\tembedding = torch.cat([embedding, sentence_embedding], 1)\n",
    "\n",
    "\t# print(f'shape: {embeddings.shape}')\n",
    "\t\tsum_embedding=torch.sum(embedding, 1)\n",
    "\t\tnorm_embedding= torch.nn.functional.normalize(sum_embedding, dim=0)\n",
    "\t\tnorm_embedding=torch.unsqueeze(norm_embedding, dim= -1)\n",
    "\n",
    "\t\tnorm_transposed=torch.transpose(norm_embedding, 0, 1)\n",
    "\n",
    "\t\tembeddings=torch.cat([embeddings, norm_transposed], 0)\n",
    "\t# print(norm_embeddings.shape)\n",
    "\treturn embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# word_embeddings=torch.tensor([extract_bert_embeddings(sentences) for sentences in sentence_list])\n",
    "\n",
    "word_embeddings=extract_bert_embeddings(sentence_list)\n",
    "male_embeddings=extract_bert_embeddings([gender_term_sentences['male']])\n",
    "female_embeddings=extract_bert_embeddings([gender_term_sentences['female']])\n",
    "print(word_embeddings)\n",
    "print(male_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender bias\n",
    "\n",
    "gender_bias_dict={}\n",
    "males=torch.tensordot(word_embeddings, male_embeddings[0], dims=1)\n",
    "females=torch.tensordot(word_embeddings, female_embeddings[0], dims=1)\n",
    "\n",
    "# gender_bias_list=[]\n",
    "for w, m, f in zip(word_list, males, females):\n",
    "    gender_bias_dict[w]=m-f\n",
    "\n",
    "gender_bias_list=list(gender_bias_dict.items())\n",
    "sorted(gender_bias_list, key= lambda x: x[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pig')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "782f229df86a3f87331e45003869958aca32dec6c75eeee8aabd6e53207a921b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
