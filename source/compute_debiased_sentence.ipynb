{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install pickle5\n",
    "%pip install mpld3\n",
    "%pip install scikit-learn\n",
    "%pip install pattern3\n",
    "%pip install nltk\n",
    "%pip install pattern"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Bert Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# debiased_model = \"sent_debiased\"\n",
    "# folder_num = \"2.\"\n",
    "# model_path = \"../debiased_models/sent_debias/debias-BERT/experiments/acl2020-results/QNLI/debiased_final_final\"\n",
    "# model = BertModel.from_pretrained(model_path, output_hidden_states = True)\n",
    "\n",
    "debiased_model = \"contextualised\"\n",
    "folder_num = \"3.\"\n",
    "model_path = \"../debiased_models/contextualised-embeddings-bert\"\n",
    "model = BertModel.from_pretrained(model_path, output_hidden_states = True)\n",
    "\n",
    "# debiased_model = \"cds\"\n",
    "# folder_num = \"4.\"\n",
    "# model_path = \"../debiased_models/cds.pt\"\n",
    "# model = BertForMaskedLM.from_pretrained('bert-base-uncased',\n",
    "#                                         output_attentions = False,\n",
    "#                                         output_hidden_states = True)\n",
    "# model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "save_path = f\"../data/extracted/{folder_num} {debiased_model}/{debiased_model}_sentence_\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open, Save, and Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "from tqdm import tqdm \n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "def dump_pklfile(file, filepath, size):\n",
    "\twith open(filepath, \"wb\") as f:\n",
    "\t\tif size == 0:\n",
    "\t\t\tpickle.dump(file, f)\n",
    "\t\telif size > 0:\n",
    "\t\t\tpickle.dump(file[:size], f)\n",
    "\t\telse:\n",
    "\t\t\tpickle.dump(file[size:], f)\n",
    "\n",
    "\n",
    "def open_pklfile(filepath, size):\n",
    "\twith open(filepath, \"rb\") as f:\n",
    "\t\tif (size == 0):\n",
    "\t\t\treturn pickle.load(f)\n",
    "\t\treturn (pickle.load(f))[0:size]\n",
    "\n",
    "\n",
    "target_position = [(3, -2), (3, -2), (3, -2), (3, -2), (2, -4), (2, -4), (3, -2), (3, -2), (3, -2), (2, -4), (2, -4)]\n",
    "\n",
    "def extract_bert_embeddings(sentence_list):\n",
    "\t# tensor for stacking embeddings\n",
    "\tembeddings = torch.empty(0, device=device)\n",
    "\n",
    "\tfor sentences in tqdm(sentence_list):\n",
    "\t\tembedding = torch.empty(0, device=device)\n",
    "\t\tfor i, sentence in enumerate(sentences):\n",
    "\t\t\t# Map the token strings to their vocabulary indeces.\n",
    "\t\t\tmarked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "\t\t\ttokenized_text = tokenizer.tokenize(marked_text)\n",
    "\t\t\t\n",
    "\t\t\t# handling such as \"wedding_dress\"\n",
    "\t\t\ttokenized_text = [token for token in tokenized_text if token != '_']\n",
    "\n",
    "\t\t\t# Split the sentence into tokens.\n",
    "\t\t\tindexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\t\t\tsegments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "\t\t\t# Convert inputs to PyTorch tensors\n",
    "\t\t\ttokens_tensor = torch.tensor([indexed_tokens], device=device)\n",
    "\t\t\tsegments_tensors = torch.tensor([segments_ids], device=device)\n",
    "\n",
    "\t\t\t# Put the model in \"evaluation\" mode,meaning feed-forward operation.\n",
    "\t\t\tmodel.eval()\n",
    "\n",
    "\t\t\t# Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\toutputs = model(tokens_tensor, segments_tensors).hidden_states\n",
    "\t\t\t\tlast_four_hidden_states = outputs[-4:]\n",
    "\t\t\t\tconcated_hidden_states = torch.cat(last_four_hidden_states, dim=2)\n",
    "\n",
    "\t\t\t\tstart_position, end_position = target_position[i][0], target_position[i][1]\n",
    "\t\t\t\tsentence_embedding = torch.sum(torch.stack([concated_hidden_states[:, start_position], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tconcated_hidden_states[:, end_position - 1]]), 0)\n",
    "\n",
    "\t\t\t\t# average of entire sentence\n",
    "\t\t\t\t# concated_hidden_states = torch.squeeze(concated_hidden_states)\n",
    "\t\t\t\t# sentence_embedding = torch.mean(concated_hidden_states, dim=0)\n",
    "\t\t\t\t# sentence_embedding = torch.unsqueeze(sentence_embedding, dim=-1)\n",
    "\n",
    "\t\t\tembedding = torch.cat([embedding, sentence_embedding], 1)\n",
    "\n",
    "\t\tsum_embedding = torch.sum(embedding, 1)\n",
    "\t\tnorm_embedding = torch.nn.functional.normalize(sum_embedding, dim=0)\n",
    "\t\tnorm_embedding = torch.unsqueeze(norm_embedding, dim=-1)\n",
    "\t\tnorm_transposed = torch.transpose(norm_embedding, 0, 1)\n",
    "\n",
    "\t\tembeddings = torch.cat([embeddings, norm_transposed], 0)\n",
    "\n",
    "\treturn embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Sentence Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "\n",
    "SINGULAR_NOUN_TEMPLATES = (\n",
    "    'This is {article} {term}.',\n",
    "    'That is {article} {term}.',\n",
    "    'There is {article} {term}.',\n",
    "    'Here is {article} {term}.',\n",
    "    'The {term} is here.',\n",
    "    'The {term} is there.',\n",
    ")\n",
    "\n",
    "PLURAL_NOUN_TEMPLATES = (\n",
    "    'These are {term}.',\n",
    "    'Those are {term}.',\n",
    "    'They are {term}.',\n",
    "    'The {term} are here.',\n",
    "    'The {term} are there.',\n",
    ")\n",
    "\n",
    "def fill_template(template, term):\n",
    "    article = (\n",
    "        'an'\n",
    "        if (\n",
    "            (\n",
    "                term.startswith('honor') or any(\n",
    "                    term.startswith(c) for c in 'aeiouAEIOU'\n",
    "                )\n",
    "            ) and not (\n",
    "                term.startswith('European') or term.startswith('Ukrainian')\n",
    "            )\n",
    "        )\n",
    "        else 'a'\n",
    "    )\n",
    "    sentence = template.format(article=article, term=term)\n",
    "    return sentence[0].upper() + sentence[1:]\n",
    "\n",
    "\n",
    "def generate_noun_sentences(vocab):\n",
    "    tags = [(word, tag) for w in vocab for word, tag in nltk.pos_tag([w])]\n",
    "    nouns = [word for word, tag in tqdm(tags) if tag.startswith(\"N\") and '___' not in word and word is not \"_\"]\n",
    "    w2i = {w: i for i, w in enumerate(nouns)}\n",
    "\n",
    "    sentence_list = []\n",
    "    for term in tqdm(nouns):\n",
    "        singular_term = singularize(term)\n",
    "        sentences = []\n",
    "        sentences += [fill_template(template, singular_term) for template in SINGULAR_NOUN_TEMPLATES]\n",
    "        plurar_term = pluralize(term)\n",
    "        sentences += [fill_template(template, plurar_term) for template in PLURAL_NOUN_TEMPLATES]\n",
    "        sentence_list.append(sentences)\n",
    "    return w2i, nouns, sentence_list\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings: Restricted Embeddings (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26189\n",
      "26189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26189/26189 [00:00<00:00, 2667685.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18447/18447 [00:01<00:00, 10087.75it/s]\n",
      "100%|██████████| 18447/18447 [22:01<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/extracted/3. contextualised/contextualised_sentence_\n"
     ]
    }
   ],
   "source": [
    "vocab = open_pklfile(\"../data/extracted/0. original/original_word_2016_restricted_vocab.pkl\", 0)\n",
    "w2i, nouns, sentence_list = generate_noun_sentences(vocab)\n",
    "lim_wv = extract_bert_embeddings(sentence_list)\n",
    "dump_pklfile(lim_wv, f\"{save_path}2016_restricted_embeddings.pkl\", 0)\n",
    "print(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings: Restricted Embeddings (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47698\n",
      "47698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47698/47698 [00:00<00:00, 2625699.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39385/39385 [00:03<00:00, 10303.99it/s]\n",
      " 53%|█████▎    | 20768/39385 [25:20<22:49, 13.60it/s]"
     ]
    }
   ],
   "source": [
    "vocab = open_pklfile(\"../data/extracted/0. original/original_word_2018_restricted_vocab.pkl\", 0)\n",
    "w2i, nouns, sentence_list = generate_noun_sentences(vocab)\n",
    "lim_wv = extract_bert_embeddings(sentence_list)\n",
    "dump_pklfile(lim_wv, f\"{save_path}2018_restricted_embeddings.pkl\", 0)\n",
    "print(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings: Top 2500 - using words from BERT (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [01:55<00:00, 21.64it/s]\n",
      "100%|██████████| 2500/2500 [02:30<00:00, 16.60it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_male_2016 = open_pklfile(\"../data/extracted/1. bert/bert_sentence_2016_male_2500_vocab.pkl\", 0)\n",
    "lim_wv_male_2016 = extract_bert_embeddings(vocab_male_2016)\n",
    "dump_pklfile(lim_wv_male_2016, f\"{save_path}2016_male_2500_embeddings.pkl\", 0)\n",
    "\n",
    "vocab_female_2016 = open_pklfile(\"../data/extracted/1. bert/bert_sentence_2016_female_2500_vocab.pkl\", 0)\n",
    "lim_wv_female_2016 = extract_bert_embeddings(vocab_female_2016)\n",
    "dump_pklfile(lim_wv_female_2016, f\"{save_path}2016_female_2500_embeddings.pkl\", 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings: Top 2500 - using words from BERT (2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [01:45<00:00, 23.72it/s]\n",
      "100%|██████████| 2500/2500 [01:58<00:00, 21.01it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_male_2018 = open_pklfile(\"../data/extracted/1. bert/bert_sentence_2018_male_2500_vocab.pkl\", 0)\n",
    "lim_wv_male_2018 = extract_bert_embeddings(vocab_male_2018)\n",
    "dump_pklfile(lim_wv_male_2018, f\"{save_path}2018_male_2500_embeddings.pkl\", 0)\n",
    "\n",
    "vocab_female_2018 = open_pklfile(\"../data/extracted/1. bert/bert_sentence_2018_female_2500_vocab.pkl\", 0)\n",
    "lim_wv_female_2018 = extract_bert_embeddings(vocab_female_2018)\n",
    "dump_pklfile(lim_wv_female_2018, f\"{save_path}2018_female_2500_embeddings.pkl\", 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings: Gender Word File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/lists/male_sentence_file.txt\", 'r') as f:\n",
    "  male_sentences = [sentence.strip() for sentence in f.readlines()]\n",
    "male_sentence_embs = extract_bert_embeddings([male_sentences])\n",
    "dump_pklfile(male_sentence_embs, f\"{save_path}male_word_file_embeddings.pkl\", 0)\n",
    "\n",
    "with open(\"../data/lists/female_sentence_file.txt\", 'r') as f:\n",
    "  female_sentences = [sentence.strip() for sentence in f.readlines()]\n",
    "female_sentence_embs = extract_bert_embeddings([female_sentences])\n",
    "dump_pklfile(female_sentence_embs, f\"{save_path}female_word_file_embeddings.pkl\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
